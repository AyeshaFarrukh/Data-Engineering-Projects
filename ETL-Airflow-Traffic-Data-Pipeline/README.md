# ğŸš¦ ETL Airflow Traffic Data Pipeline  

## ğŸ§© Problem Statement  
National highways experience growing congestion due to fragmented toll data systems; each operator maintains traffic records in different file formats (CSV, TSV, and fixed-width text).  
As a Data Engineer, the goal is to design an **automated ETL pipeline using Apache Airflow** that:  
- Extracts data from multiple file formats  
- Transforms and consolidates the datasets into a unified structure  
- Loads the cleaned output into a staging area for analytics  

This project demonstrates building a **production-ready ETL workflow** using **BashOperator** in Apache Airflow to orchestrate all extraction, transformation, and loading steps.  

---

## âš™ï¸ Tech Stack  
- **Apache Airflow** (DAG orchestration)  
- **BashOperator** (task automation)  
- **Python 3 & Shell scripting**  
- **CSV / TSV / Fixed-Width File Processing**  

---

## ğŸ“‚ Project Structure  

```text
ETL-Airflow-Traffic-Data-Pipeline/
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ etl_toll_data_dag.py         # Airflow DAG definition
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ vehicle-data.csv
â”‚   â”œâ”€â”€ tollplaza-data.tsv
â”‚   â”œâ”€â”€ payment-data.txt
â”‚   â””â”€â”€ final_staging.csv
â”œâ”€â”€ screenshots/
â”‚   â”œâ”€â”€ task1.1_dag_arguments.png
â”‚   â”œâ”€â”€ task2.4_fixedwidth_extract.png
â”‚   â”œâ”€â”€ task2.7_pipeline_definition.png
â”‚   â””â”€â”€ task3.4_dag_monitor.png
â””â”€â”€ README.md
